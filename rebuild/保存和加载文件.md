- [1. 保存和加载文件](#1-保存和加载文件)
    - [1.0.1. 任何变量](#101-任何变量)
    - [1.0.2. state\_dict 权重](#102-state_dict-权重)
    - [1.0.3. map\_location](#103-map_location)

---
# 1. 保存和加载文件

```python
# (变量，文件名)
torch.save(model.state_dict(), 'model_weights.pth')
ckpt = torch.load('model_weights.pth', map_location='cpu')
```
能保存什么：
- 任何变量
- `model.state_dict()`
- `optimizer.state_dict()`

### 1.0.1. 任何变量

```python
import torch

x = torch.arange(4)
torch.save(x, 'x-file')
```

我们现在可以将存储在文件中的数据读回内存。

```python
x2 = torch.load('x-file')
```




    tensor([0, 1, 2, 3])

我们可以存储一个**张量列表**，然后把它们读回内存。

```python
y = torch.zeros(4)
torch.save([x, y], 'x-files')
x2, y2 = torch.load('x-files')
(x2, y2)
```




    (tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))



我们甚至可以写入或读取从字符串映射到张量的**字典**。当我们要读取或写入模型中的所有权重时，这很方便。

```python
mydict = {'x': x, 'y': y}
torch.save(mydict, 'mydict')
mydict2 = torch.load('mydict')
mydict2
```




    {'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}

### 1.0.2. state_dict 权重
```python
model = YourModel().to(device)
# save
torch.save(model.state_dict(), 'model_weights.pth')
# load
model.load_state_dict(ckpt)

optimizer = torch.optim.SGD(model.parameters(),lr=0.001,momentum=0.9)
# save
torch.save(optimizer.state_dict(), 'optimizer_weights.pth')
# load
optimizer.load_state_dict(ckpt)
```
重新训练或者微调时，没事。但如果只用于推理，还要加这个。
```python
model.eval()  # Failing to do this will yield inconsistent inference results
```
### 1.0.3. map_location
```python
# default None: 原本保存在CPU还是GPU的位置，现在去出来还放到那里
# 但如果原本是GPU，你只有CPU，那么就会出错。所以下面就是指定到别的位置上。
torch.load('tensors.pt')  # None

# Load all tensors onto the CPU
torch.load('tensors.pt', map_location='cpu')    # str

# Load all tensors onto the GPU 0
torch.load('tensors.pt', map_location=torch.device('cuda:0')) # torch.device类型

# Map tensors from GPU 1 to GPU 0
torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'}) # dict
```

> 例子

```python
ckpt = {
    'global_step': global_step,
    'network_fn_state_dict': render_kwargs_train['network_fn'].state_dict(),
    'optimizer_state_dict': optimizer.state_dict()
}
torch.save(ckpt, 'ckpt.pth')


ckpt = torch.load('ckpt.pth')

start = ckpt['global_step']
optimizer.load_state_dict(ckpt['optimizer_state_dict'])
model.load_state_dict(ckpt['network_fn_state_dict'])
```

