[toc]

dev_parameter_shrink是最新

2025-03-20 windows 11



## face-seg

```bash
git clone git@github.com:sword4869/face_parsing.git
cd face_parsing

# 直接用pytorch3d的环境
conda activate cu124win
pip install .
```

```bash
# neck和head前景（反选背景和cloth）
$ subject='bala'
$ face_parsing  --ckpt /home/lab/Documents/face-seg/pretrain/79999_iter.pth \
    --img_path /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/imgs \
    --save_root /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/parsing \
	--chosen_parts 0 16 --chosen_filename neckhead --chosen_reverse

# mouth u_lip 和 lip
$ face_parsing  --ckpt /home/lab/Documents/face-seg/pretrain/79999_iter.pth \
    --img_path /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/imgs \
    --save_root /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/parsing \
	--chosen_parts 11 12 13 --chosen_filename mouth
```

## MICA

```bash
git clone https://github.com/Zielon/MICA.git
cd MICA


conda create -n MICA python=3.10 -y
conda activate MICA
pip install -r requirements.txt
```

```
--index-url https://download.pytorch.org/whl/cu124
--extra-index-url https://mirrors.bfsu.edu.cn/pypi/web/simple
torch==2.4.0+cu124
torchvision==0.19.0

loguru==0.6.0
insightface==0.7
opencv-python==4.7.0.72
numpy==1.23.5
trimesh==3.16.4
scikit-image==0.19.3
onnx==1.13.0
onnxruntime==1.13.1
yacs==0.1.8
face-alignment==1.3.5
chumpy==0.70
```

```bash
python demo.py -i demo/input -o demo/output
```

- 输入：

  - `demo\input\duda.jpg` 放入全身的第一帧 

- 输出：

  - `demo\output\duda\identity.npy` 身份


## pytorch3d-0.7.8 [12.4.md](..\..\环境\pytorch3d\安装\12.4.md) 

## metrical-tracker

```bash
git clone git@github.com:Zielon/metrical-tracker.git
cd metrical-tracker
```



```
(base) PS D:\other\nchu\paper\experiment1\code\metrical-tracker> mytree
├── LICENSE
...
├── data
    ├── head_template_color.obj
    ├── head_template_mesh.mtl
    ├── head_template_mesh.obj
    ├── landmark_embedding.npy
    ├── uv_mask_eyes.png
    ├── uv_template.obj
    └── FLAME2020
        ├── FLAME_masks.pkl
        ├── FLAME_texture.npz
        └── generic_model.pkl
├── datasets
...
```

- `metrical-tracker-data.zip`：`data`文件夹

- `checkpoints.zip`：`~\.cache\torch\hub\checkpoints`
  - `s3fd-619a316812.pth`
  - `-cd938726ad.zip`




用到pytorch3d

```bash
conda activate pyt3dcu124
pip install -r requirements.txt
conda install ffmpeg
```

```
--index-url https://download.pytorch.org/whl/cu124
--extra-index-url https://mirrors.bfsu.edu.cn/pypi/web/simple
torch==2.4.0+cu124
torchvision==0.19.0


opencv-contrib-python==4.7.0.72
opencv-python==4.7.0.72
numpy==1.23.5

absl-py==1.4.0
attrs==22.2.0
cachetools==5.3.0
chumpy==0.70
contourpy==1.0.7
cycler==0.11.0
face-alignment==1.3.5
flatbuffers==23.3.3
fonttools==4.39.2
grpcio==1.51.3
imageio==2.26.1
importlib-metadata==6.1.0
importlib-resources==5.12.0
kiwisolver==1.4.4
lazy-loader==0.1
llvmlite==0.39.1
loguru==0.6.0
markdown==3.4.1
markupsafe==2.1.2
matplotlib==3.7.1
mediapipe==0.10.5
networkx==3.0
numba==0.56.4
oauthlib==3.2.2
packaging==23.0
protobuf==3.20.3
pyasn1==0.4.8
pyasn1-modules==0.2.8
pyparsing==3.0.9
python-dateutil==2.8.2
pywavelets==1.4.1
requests-oauthlib==1.3.1
rsa==4.9
scikit-image==0.20.0
scipy==1.9.1
sounddevice==0.4.6
tensorboard==2.12.0
tensorboard-data-server==0.7.0
tensorboard-plugin-wit==1.8.1
tifffile==2023.3.15
trimesh==3.20.2
werkzeug==2.2.3
zipp==3.15.0
ffmpeg==1.4
```

```bash
python tracker.py --cfg ./configs/actors/duda.yml
```

- 输入
  - `input\duda\identity.npy` 身份
  - `input\duda\video.mp4` 全身的视频

- 输出：
  - `input\duda\source` 25fps的人头裁剪
  - `output\duda\checkpoint`  `.frame`文件



source被其重命名为 imgs，并让其从0开始。

## RobustVideoMatting

```bash
git clone git@github.com:sword4869/RobustVideoMatting.git
cd RobustVideoMatting

# 只需要pytorch
conda activate pyt3dcu124
pip install .
```

```bash
# D:\other\nchu\paper\experiment1\code\dataset\nf_01\imgs 
# 会自动创建 alpha 文件夹
rvm --variant resnet50 `
--checkpoint D:\other\nchu\paper\experiment1\code\RobustVideoMatting\model\rvm_resnet50.pth `
--device cuda `
--input-source D:\other\nchu\paper\experiment1\code\dataset\nf_01\imgs `
--output-type png_sequence `
--output-alpha "alpha.mp4" `
--seq-chunk 1
```

还需要重命名，少一位数字0.

## [face_parsing](https://github.com/sword4869/face_parsing)

`checkpoints.zip`：`~\.cache\torch\hub\checkpoints`

- `resnet18-5c106cde.pth`

```bash
git clone git@github.com:sword4869/face_parsing.git
cd face_parsing

conda activate pyt3dcu124
pip install .
```

- 输入： `input\duda\source`

- 输出：
  - head前景（反选背景和cloth）
  - neck

```powershell
$subject='bala'
face_parsing  --ckpt D:\other\nchu\paper\experiment1\code\face_parsing\pretrain\79999_iter.pth `
    --img_path D:\other\nchu\paper\experiment1\code\dataset\$subject\imgs `
    --save_root D:\other\nchu\paper\experiment1\code\dataset\$subject\parsing `
	--chosen_parts 0 16 --chosen_reverse --chosen_filename neckhead 

	
face_parsing  --ckpt D:\other\nchu\paper\experiment1\code\face_parsing\pretrain\79999_iter.pth `
    --img_path D:\other\nchu\paper\experiment1\code\dataset\$subject\imgs `
    --save_root D:\other\nchu\paper\experiment1\code\dataset\$subject\parsing `
	--chosen_parts 11 12 13 --chosen_filename mouth
```

```
# neck和head前景（反选背景和cloth）
subject='bala'
face_parsing  --ckpt /home/lab/Documents/face-seg/pretrain/79999_iter.pth \
    --img_path /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/imgs \
    --save_root /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/parsing \
	--chosen_parts 0 16 --chosen_reverse --chosen_filename neckhead 

	
face_parsing  --ckpt /home/lab/Documents/face-seg/pretrain/79999_iter.pth \
    --img_path /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/imgs \
    --save_root /media/lab/新加卷/DataSet/FlashAvatar/flash/dataset/$subject/parsing \
	--chosen_parts 11 12 13 --chosen_filename mouth
```

